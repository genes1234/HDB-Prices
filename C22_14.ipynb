{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b331eb08",
   "metadata": {},
   "source": [
    "# Import Basic Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9ff5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e3a92",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "## HDBdata was obtained from https://beta.data.gov.sg/datasets/d_8b84c4ee58e3cfc0ece0d773c8ca6abc/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be4b1fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>town</th>\n",
       "      <th>flat_type</th>\n",
       "      <th>block</th>\n",
       "      <th>street_name</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>lease_commence_date</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>resale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>2 ROOM</td>\n",
       "      <td>406</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Improved</td>\n",
       "      <td>1979</td>\n",
       "      <td>61 years 04 months</td>\n",
       "      <td>232000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>108</td>\n",
       "      <td>ANG MO KIO AVE 4</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1978</td>\n",
       "      <td>60 years 07 months</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>602</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>262000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>465</td>\n",
       "      <td>ANG MO KIO AVE 10</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 01 month</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>601</td>\n",
       "      <td>ANG MO KIO AVE 5</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>67.0</td>\n",
       "      <td>New Generation</td>\n",
       "      <td>1980</td>\n",
       "      <td>62 years 05 months</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     month        town flat_type block        street_name storey_range  \\\n",
       "0  2017-01  ANG MO KIO    2 ROOM   406  ANG MO KIO AVE 10     10 TO 12   \n",
       "1  2017-01  ANG MO KIO    3 ROOM   108   ANG MO KIO AVE 4     01 TO 03   \n",
       "2  2017-01  ANG MO KIO    3 ROOM   602   ANG MO KIO AVE 5     01 TO 03   \n",
       "3  2017-01  ANG MO KIO    3 ROOM   465  ANG MO KIO AVE 10     04 TO 06   \n",
       "4  2017-01  ANG MO KIO    3 ROOM   601   ANG MO KIO AVE 5     01 TO 03   \n",
       "\n",
       "   floor_area_sqm      flat_model  lease_commence_date     remaining_lease  \\\n",
       "0            44.0        Improved                 1979  61 years 04 months   \n",
       "1            67.0  New Generation                 1978  60 years 07 months   \n",
       "2            67.0  New Generation                 1980  62 years 05 months   \n",
       "3            68.0  New Generation                 1980   62 years 01 month   \n",
       "4            67.0  New Generation                 1980  62 years 05 months   \n",
       "\n",
       "   resale_price  \n",
       "0      232000.0  \n",
       "1      250000.0  \n",
       "2      262000.0  \n",
       "3      265000.0  \n",
       "4      265000.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign data file to a variable\n",
    "\n",
    "file = \"ResaleflatpricesbasedonregistrationdatefromJan2017onwards.csv\"\n",
    "\n",
    "# Create a Data Frame \n",
    "\n",
    "hdb_df = pd.read_csv(file)\n",
    "hdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167801a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a temporary Data Frame to view unique values for relevant categorical columns\n",
    "\n",
    "temp_df = hdb_df.drop(['month','block','street_name','floor_area_sqm','lease_commence_date',\n",
    "                   'remaining_lease','resale_price'],axis = 1)\n",
    "\n",
    "for i in temp_df:\n",
    "    print(i,':')\n",
    "    print(temp_df[i].unique())\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing data\n",
    "\n",
    "hdb_df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data types of each column\n",
    "\n",
    "hdb_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7551d2",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d758d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)Creating 2 new columns ('years' and 'months').\n",
    "# 2)Extract substrings using a regular expression pattern.\n",
    "# 3)'\\d+' Shorthand character class that matches any digit (0-9), one of more times consecutively.\n",
    "# 4)\"years\" year followed by an optional \"s\", allowing both 'year' and 'years' to match.\n",
    "# 5)Converts extracted values to float.\n",
    "\n",
    "hdb_df['years'] = hdb_df['remaining_lease'].str.extract(r'(\\d+) years?').astype(float) \n",
    "hdb_df['months'] = hdb_df['remaining_lease'].str.extract(r'(\\d+) months?').astype(float)\n",
    "\n",
    "# Fills missing values in the 'months' column with 0 using fillna(0, inplace=True)\n",
    "\n",
    "hdb_df['months'].fillna(0, inplace=True)\n",
    "\n",
    "# Convert to numerical representation (total months)\n",
    "\n",
    "hdb_df['remaining_lease_months'] = hdb_df['years'] * 12 + hdb_df['months']\n",
    "\n",
    "# Clean Storey (e.g. if storey_range = 10 TO 12, storey = 11)\n",
    "\n",
    "hdb_df[['start', 'end']] = hdb_df['storey_range'].str.split(' TO ', expand=True).astype(int)\n",
    "hdb_df['storey'] = (hdb_df['start'] + hdb_df['end']) / 2\n",
    "\n",
    "# Drop irrelevant columns\n",
    "\n",
    "hdb_df = hdb_df.drop(['month', 'street_name', 'block', 'years', 'months', \n",
    "                      'remaining_lease', 'lease_commence_date', 'start','end'], axis=1)\n",
    "\n",
    "# Check for any missing data again\n",
    "hdb_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview cleaned data\n",
    "\n",
    "hdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a467be",
   "metadata": {},
   "source": [
    "## Determining Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ede15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Data Frame only consisting of 'float' data types\n",
    "\n",
    "numeric_df = hdb_df.select_dtypes(include=['float'])\n",
    "\n",
    "# Create correlation heat map\n",
    "\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sb.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f6653",
   "metadata": {},
   "source": [
    "# Bivariate Prediction\n",
    "## Since Floor Area Sqm has the highest correlation with Resale Price (0.6), we decide to perform further analysis\n",
    "## First, removing outliers, followed by creating a linear regression model to see if Floor Area Sqm can be used to predict the Resale Price\n",
    "\n",
    "Use IQR if:\n",
    "\n",
    "Your dataset is relatively small.\n",
    "The distribution of your data is approximately Gaussian or symmetric.\n",
    "Prefer a simple and computationally efficient method.\n",
    "\n",
    "Use LOF if:\n",
    "\n",
    "Your dataset has a complex distribution or contains clusters of different densities.\n",
    "You have a larger dataset or high-dimensional data.\n",
    "You need a method that is more robust to outliers and can handle non-Gaussian distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c06214",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f627e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LocalOutlierFactor from sklearn.neighbors\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame with only Floor Area Sqm and Resale Price\n",
    "\n",
    "fsqm_price_df = pd.DataFrame(hdb_df[[\"floor_area_sqm\", \"resale_price\"]])\n",
    "\n",
    "# Set the Parameters for Neighborhood\n",
    "\n",
    "num_neighbors = 20      # Number of Neighbors\n",
    "cont_fraction = 0.1    # Fraction of Anomalies\n",
    "\n",
    "# Create Anomaly Detection Model using LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors = num_neighbors, contamination = cont_fraction)\n",
    "\n",
    "# Fit the Model on the Data and Predict Anomalies\n",
    "lof.fit(fsqm_price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb42431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict the Anomalies\n",
    "\n",
    "labels = lof.fit_predict(fsqm_price_df)\n",
    "\n",
    "# Append Labels to the Data\n",
    "\n",
    "A_labeled = fsqm_price_df.copy()\n",
    "A_labeled[\"Anomaly\"] = pd.Categorical(labels)\n",
    "\n",
    "# Summary of the Anomaly Labels\n",
    "\n",
    "sb.countplot(x=\"Anomaly\",data=A_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Anomalies\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(16,8))\n",
    "plt.scatter(x = \"floor_area_sqm\", y = \"resale_price\", c = \"Anomaly\", cmap = 'viridis', data = A_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430386d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable for outliers\n",
    "\n",
    "outlier_indices = np.where(labels == -1)[0]\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "\n",
    "fsqm_price_clean_df = A_labeled.drop(index=outlier_indices)\n",
    "\n",
    "# Check if any changes from cleaning\n",
    "\n",
    "print(\"Total number of rows (Before):\", len(fsqm_price_df))\n",
    "print(\"Total number of rows (After):\", len(fsqm_price_clean_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d727e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Resale Price against Floor Area Sqm\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(16,8))\n",
    "plt.scatter(x = \"floor_area_sqm\", y = \"resale_price\", data = fsqm_price_clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bf9e0",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48877e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38983a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor -> Floor Area Sqm\n",
    "# Response  -> Resale Price\n",
    "\n",
    "# Random Split of train and test data set, test size = 0.2\n",
    "\n",
    "x = fsqm_price_clean_df[['floor_area_sqm']] \n",
    "y = fsqm_price_clean_df['resale_price']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "\n",
    "linreg.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using test data\n",
    "\n",
    "y_pred = linreg.predict(x_test)\n",
    "\n",
    "# Plot of original data and regression line\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(x_test, y_test, color='blue', label='Original Data')\n",
    "plt.plot(x_test, y_pred, color='red', linewidth=2, label='Linear Regression')\n",
    "plt.xlabel('Floor Area (sqm)')\n",
    "plt.ylabel('Resale Price')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = m(Floor_sqm)+C\n",
    "\n",
    "print(\"Intercept:\", linreg.intercept_)\n",
    "print(\"Gradient:\", linreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e32a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining how well the data fits the regression model\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea3d0b",
   "metadata": {},
   "source": [
    "## Are there trends that can be observed between Resale Price and Town?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c34236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Data Frame with only Town and Resale Price \n",
    "\n",
    "town_price_df = pd.DataFrame(hdb_df[['town', 'resale_price']])\n",
    "\n",
    "# Create a Data Frame with only Flat Type and Resale Price (For later use)\n",
    "\n",
    "flat_resale = pd.DataFrame(hdb_df[['flat_type', 'resale_price']])\n",
    "\n",
    "# Create box plot of Resale Prices of each Town\n",
    "\n",
    "plt.figure(figsize = (10, 20))\n",
    "sb.boxplot(x = 'resale_price', y = 'town', data = town_price_df)\n",
    "plt.title('Resale Prices by Town')\n",
    "plt.xlabel('Resale Price')\n",
    "plt.ylabel('Town')\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "# Create a Data Frame for the median price of each town\n",
    "\n",
    "median_prices = town_price_df.groupby('town')['resale_price'].median().reset_index()\n",
    "\n",
    "# Styling (insert median price on the right)\n",
    "\n",
    "for index, row in median_prices.iterrows():\n",
    "    plt.text(1700000, index, f'{row[\"town\"]} ({row[\"resale_price\"]})', fontsize=8, va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb90b3",
   "metadata": {},
   "source": [
    "## Multi-Variate Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "#MinMaxScaler standardizes features by scaling to a given range; brings the numerical values to a uniform scale \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf876ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdb_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previously created 'storey' column\n",
    "\n",
    "hdb_df = hdb_df.drop(columns=['storey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d1d36",
   "metadata": {},
   "source": [
    "### pd.get_dummies is a way to represent categorical variables as binary vectors, where each category becomes a separate column, and a value of 1 or 0 indicates a True or False value of that category for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35945e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_df = pd.get_dummies(hdb_df,columns=[\"town\", \"flat_type\", \"flat_model\", \"storey_range\"], dtype = 'int')\n",
    "hdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc906c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare x and y data for linear regression model\n",
    "# y = Resale Price\n",
    "# x = All other features\n",
    "\n",
    "y = hdb_df['resale_price']\n",
    "x = hdb_df.drop(columns=['resale_price'])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test, Supervised learning\n",
    "# 70% training data and 30% test data\n",
    "# Setting random states to a specific values ensures that the random splitting is reproducible\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2)\n",
    "\n",
    "# Normalisation, scaling and transforming the features of a dataset to a standard range\n",
    "\n",
    "scaler_x = MinMaxScaler(feature_range=(0,1))\n",
    "x_train_scaled = scaler_x.fit_transform(x_train)\n",
    "x_test_scaled = scaler_x.transform(x_test)\n",
    "x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda941a",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multiple linear regression model\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "\n",
    "lin_reg.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Compute predictions from the test set\n",
    "\n",
    "y_pred = lin_reg.predict(x_test_scaled)\n",
    "\n",
    "# Create a plot to visualize actual vs predicted Resale Price (first 250 samples)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Create an array of sample indices for the x-axis\n",
    "sample_indices = range(250)\n",
    "\n",
    "# Slice the actual and predicted values to include only the first 500 samples\n",
    "y_test_slice = y_test[:250]\n",
    "y_pred_slice = y_pred[:250]\n",
    "\n",
    "# Plot the actual values\n",
    "plt.plot(sample_indices, y_test_slice, label=\"Actual\", linestyle='-')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(sample_indices, y_pred_slice, label=\"Predicted\", linestyle='-')\n",
    "\n",
    "#Label plot\n",
    "plt.ylabel('Sales Prediction')\n",
    "plt.xlabel('Sample Number')\n",
    "plt.title('Actual vs. Predicted (First 250 Samples)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec21e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize predicted vs actual Resale Price\n",
    "\n",
    "plt.scatter(y_test, y_pred, label='Data Points')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', \n",
    "         linestyle='--', label='Perfect Predictions')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values with Perfect Predictions Line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create variables for R2 value, mean squared error, root mean squared error and\n",
    "# mean absolute error, based on test data\n",
    "\n",
    "r_squared = lin_reg.score(x_test_scaled, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R^2:', r_squared)\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Root Mean Square Error:', rmse)\n",
    "print('Mean Absolute Error:', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490504d",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "### This section aims to identify common features of the data sets with the highest absolute error between the actual and predicted Resale Price, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable of the absolute error between each predicted and actual Resale Price\n",
    "\n",
    "absolute_error = abs(y_test - y_pred)\n",
    "\n",
    "# Convert to it to a Data Frame\n",
    "\n",
    "absolute_error_df = pd.DataFrame(absolute_error)\n",
    "\n",
    "# Determine data sets with the top 100 largest absolute error\n",
    "\n",
    "top_absolute_error = absolute_error_df.nlargest(100,'resale_price')\n",
    "\n",
    "# Create a new Data Frame consisting of the top 100 data sets\n",
    "\n",
    "# First, identify the index\n",
    "top_indices = top_absolute_error.index\n",
    "\n",
    "# Next, locate the index in the original data frame, and assign it to a new data frame\n",
    "top_absolute_error_df = hdb_df.loc[hdb_df.index.isin(top_indices)] \n",
    "\n",
    "# Drop irrelevant columns\n",
    "top_absolute_error_df = top_absolute_error_df.drop(['floor_area_sqm','resale_price',\n",
    "                                                    'remaining_lease_months'], axis = 1)\n",
    "\n",
    "top_absolute_error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcab0ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store counts\n",
    "feature_counts = {}\n",
    "\n",
    "# Iterate through each row\n",
    "for index, row in top_absolute_error_df.iterrows():\n",
    "  # Find non-zero columns using boolean indexing\n",
    "  non_zero_cols = row.ne(0).values  # 'ne' stands for not equal\n",
    "  # Get column names based on boolean indexing\n",
    "  column_names = top_absolute_error_df.columns[non_zero_cols]\n",
    "\n",
    "  # Update feature counts in the dictionary\n",
    "  for col in column_names:\n",
    "    if col not in feature_counts:\n",
    "        feature_counts[col] = 0\n",
    "    feature_counts[col] += 1\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_counts = pd.DataFrame.from_dict(feature_counts, orient='index', columns=['count'])\n",
    "df_counts = df_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Print the DataFrame with feature names and counts\n",
    "df_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b9dc5",
   "metadata": {},
   "source": [
    "### It can be observed that there may common features between the top data sets with the largest absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create box plot of Resale Prices of each Town\n",
    "\n",
    "plt.figure(figsize = (10, 20))\n",
    "sb.boxplot(x = 'resale_price', y = 'town', data = town_price_df)\n",
    "plt.title('Resale Prices by Town')\n",
    "plt.xlabel('Resale Price')\n",
    "plt.ylabel('Town')\n",
    "plt.xticks(rotation = 45)\n",
    "\n",
    "# Create a Data Frame for the median price of each town\n",
    "\n",
    "median_prices = town_price_df.groupby('town')['resale_price'].median().reset_index()\n",
    "\n",
    "# Styling (insert median price on the right)\n",
    "\n",
    "for index, row in median_prices.iterrows():\n",
    "    plt.text(1700000, index, f'{row[\"town\"]} ({row[\"resale_price\"]})', fontsize=8, va='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create box plot of Resale Prices of each Flat Type\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sb.boxplot(x='resale_price', y='flat_type', data=flat_resale)\n",
    "plt.title('Resale Prices by Flat Type')\n",
    "plt.xlabel('Resale Price')\n",
    "plt.ylabel('Flat Type')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "median_prices_flattypes = flat_resale.groupby('flat_type')['resale_price'].median().reset_index()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e11d0c",
   "metadata": {},
   "source": [
    "# Additional Info: Random Forest\n",
    "### In this section, random forest machine learning algorithm was explored, to determine if it will be a better model for predicting Resale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cde6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test and training data set\n",
    "\n",
    "train = hdb_df.sample(frac=0.7, random_state=101)\n",
    "test = hdb_df.drop(train.index)\n",
    "\n",
    "# Set x and y variables for test and train data\n",
    "# y = Resale Price\n",
    "# x = All other features\n",
    "\n",
    "trainY = train[\"resale_price\"]\n",
    "trainX = train.drop(columns=[\"resale_price\"])\n",
    "\n",
    "\n",
    "testY = test[\"resale_price\"]\n",
    "testX = test.drop(columns=[\"resale_price\"])\n",
    "\n",
    "# Create a regression model\n",
    "\n",
    "model = RandomForestRegressor(random_state=42).fit(trainX,trainY)\n",
    "\n",
    "\n",
    "# Compute predictions\n",
    "\n",
    "predY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e6929",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Determine relevant information (same as previous)\n",
    "# Visualize predicted vs actual Resale Price\n",
    "\n",
    "\n",
    "plt.scatter(testY, predY, label='Data Points')\n",
    "plt.plot([min(testY), max(testY)], [min(testY), max(testY)], color='red', \n",
    "         linestyle='--', label='Perfect Predictions')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values with Perfect Predictions Line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Scaling x dataset\n",
    "\n",
    "testX_scaled = scaler_x.transform(testX)\n",
    "\n",
    "# Create variables for R2 value, mean squared error, root mean squared error and\n",
    "# mean absolute error, based on test data\n",
    "\n",
    "r_squared_rf = lin_reg.score(testX_scaled, testY)\n",
    "mse_rf = mean_squared_error(testY, predY)\n",
    "rmse_rf = np.sqrt(mean_squared_error(testY, predY))\n",
    "mae_rf = mean_absolute_error(testY, predY)\n",
    "\n",
    "print('R^2:', r_squared_rf)\n",
    "print('Mean Squared Error:', mse_rf)\n",
    "print('Root Mean Square Error:', rmse_rf)\n",
    "print('Mean Absolute Error:', mae_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed8c87",
   "metadata": {},
   "source": [
    "### It is noted that although R^2 did not change much, RMSE decreased by about 37%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
